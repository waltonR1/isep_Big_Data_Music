x-airflow-common: &airflow-common
  image: apache/airflow:2.9.0
  environment: &airflow-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME}
    _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD}
    _PIP_ADDITIONAL_REQUIREMENTS: pandas requests boto3 pytrends elasticsearch
  volumes:
    - ./dags:/opt/airflow/dags
    - ./ingestion:/opt/airflow/ingestion
    - ./transform:/opt/airflow/transform
    - ./index:/opt/airflow/index
    - ./raw:/opt/airflow/raw
    - ./formatted:/opt/airflow/formatted
    - ./final:/opt/airflow/final
  user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
  depends_on:
    - postgres
    - redis

services:
  # ① 新增：初始化数据库并创建管理员账号
  airflow-init:
    <<: *airflow-common
    command: >
      bash -c '
        airflow db migrate && \
        airflow users create \
          --username ${_AIRFLOW_WWW_USER_USERNAME:-admin} \
          --password ${_AIRFLOW_WWW_USER_PASSWORD:-admin} \
          --firstname Admin --lastname User \
          --role Admin \
          --email admin@example.com
      '
    # 依赖数据库和 Redis 就行
    depends_on:
      - postgres
      - redis

  # ② 下面这些保持原样
  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8080:8080"

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler

  airflow-worker:
    <<: *airflow-common
    command: celery worker

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  redis:
    image: redis:latest

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.2
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

  localstack:
    image: localstack/localstack:latest
    ports:
      - "4566:4566"
      - "4571:4571"
    environment:
      - SERVICES=s3
      - DEFAULT_REGION=us-east-1
      - DATA_DIR=/tmp/localstack/data
    volumes:
      - "./.localstack:/tmp/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"

volumes:
  postgres-db-volume:
  esdata:
